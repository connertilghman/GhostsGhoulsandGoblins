# Random Forest Model Spec (tuneable)
#-------------------------------
rf_model <- rand_forest(
trees = 600,
mtry = tune(),   # number of predictors sampled at each split
min_n = tune()   # minimum node size
) |>
set_engine("randomForest") |>
set_mode("classification")
#-------------------------------
# Workflow
#-------------------------------
rf_wf <- workflow() |>
add_recipe(rf_recipe) |>
add_model(rf_model)
#-------------------------------
# Cross-validation (on full train data)
#-------------------------------
set.seed(123)
cv_folds <- vfold_cv(train, v = 5, strata = type)
#-------------------------------
# Tuning Grid
#-------------------------------
rf_grid <- grid_regular(
mtry(range = c(2, 8)),
min_n(range = c(1, 10)),
levels = 5
)
#-------------------------------
# Tune hyperparameters
#-------------------------------
rf_tuned <- tune_grid(
rf_wf,
resamples = cv_folds,
grid = rf_grid,
metrics = metric_set(accuracy)
)
#-------------------------------
# Select best parameters
#-------------------------------
best_params <- select_best(rf_tuned, metric = "accuracy")
#-------------------------------
# Final workflow with best params
#-------------------------------
final_rf <- finalize_workflow(rf_wf, best_params)
#-------------------------------
# Fit final model on FULL train data
#-------------------------------
final_fit <- fit(final_rf, data = train)
#-------------------------------
# Predict on test.csv
#-------------------------------
test_preds <- predict(final_fit, test) |>
bind_cols(test |> select(id))
#-------------------------------
# Prepare Kaggle submission
#-------------------------------
submission <- test_preds |>
select(id, .pred_class) |>
rename(type = .pred_class)
View(submission)
write_csv(submission, "submission.csv")
#-------------------------------
# Load Data
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
# Ensure outcome is factor
train$type <- as.factor(train$type)
#-------------------------------
# Recipe
#-------------------------------
rf_recipe <- recipe(type ~ ., data = train) |>
update_role(id, new_role = "ID") |>   # exclude id from predictors
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors())
#-------------------------------
# Random Forest Model Spec (tuneable)
#-------------------------------
rf_model <- rand_forest(
trees = 1000,
mtry = tune(),   # number of predictors sampled at each split
min_n = tune()   # minimum node size
) |>
set_engine("randomForest") |>
set_mode("classification")
#-------------------------------
# Workflow
#-------------------------------
rf_wf <- workflow() |>
add_recipe(rf_recipe) |>
add_model(rf_model)
cv_folds <- vfold_cv(train, v = 10, strata = type)
#-------------------------------
# Tuning Grid
#-------------------------------
rf_grid <- grid_regular(
mtry(range = c(2, 8)),
min_n(),
levels = 5
)
#-------------------------------
# Tune hyperparameters
#-------------------------------
rf_tuned <- tune_grid(
rf_wf,
resamples = cv_folds,
grid = rf_grid,
metrics = metric_set(accuracy)
)
#-------------------------------
# Select best parameters
#-------------------------------
best_params <- select_best(rf_tuned, metric = "accuracy")
#-------------------------------
# Final workflow with best params
#-------------------------------
final_rf <- finalize_workflow(rf_wf, best_params)
#-------------------------------
# Fit final model on FULL train data
#-------------------------------
final_fit <- fit(final_rf, data = train)
#-------------------------------
# Predict on test.csv
#-------------------------------
test_preds <- predict(final_fit, test) |>
bind_cols(test |> select(id))
#-------------------------------
# Prepare Kaggle submission
#-------------------------------
submission <- test_preds |>
select(id, .pred_class) |>
rename(type = .pred_class)
write_csv(submission, "submission.csv")
#-------------------------------
# Load Data
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
# Ensure outcome is factor
train$type <- as.factor(train$type)
#-------------------------------
# Recipe
#-------------------------------
rf_recipe <- recipe(type ~ ., data = train) |>
update_role(id, new_role = "ID") |>   # exclude id from predictors
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors())
#-------------------------------
# Random Forest Model Spec (tuneable)
#-------------------------------
rf_model <- rand_forest(
trees = 1000,
mtry = tune(),   # number of predictors sampled at each split
min_n = tune()   # minimum node size
) |>
set_engine("randomForest") |>
set_mode("classification")
#-------------------------------
# Workflow
#-------------------------------
rf_wf <- workflow() |>
add_recipe(rf_recipe) |>
add_model(rf_model)
cv_folds <- vfold_cv(train, v = 10, repeats = 5, strata = type)
#-------------------------------
# Tuning Grid
#-------------------------------
rf_grid <- grid_regular(
mtry(range = c(2, 10)),
min_n(),
levels = 5
)
#-------------------------------
# Tune hyperparameters
#-------------------------------
rf_tuned <- tune_grid(
rf_wf,
resamples = cv_folds,
grid = rf_grid,
metrics = metric_set(accuracy)
)
View(rf_tuned)
#-------------------------------
# Select best parameters
#-------------------------------
best_params <- select_best(rf_tuned, metric = "accuracy")
#-------------------------------
# Final workflow with best params
#-------------------------------
final_rf <- finalize_workflow(rf_wf, best_params)
#-------------------------------
# Fit final model on FULL train data
#-------------------------------
final_fit <- fit(final_rf, data = train)
#-------------------------------
# Predict on test.csv
#-------------------------------
test_preds <- predict(final_fit, test) |>
bind_cols(test |> select(id))
View(test_preds)
#-------------------------------
# Prepare Kaggle submission
#-------------------------------
submission <- test_preds |>
select(id, .pred_class) |>
rename(type = .pred_class)
write_csv(submission, "submission.csv")
library(catboost)
library(readr)
library(dplyr)
library(xgboost)
install.packages("xgboost")
install.packages("caret")
library(xgboost)
library(readr)
library(dplyr)
library(caret)
#-------------------------------
# Load data
#-------------------------------
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
#-------------------------------
# Prepare outcome variable
#-------------------------------
train$type <- as.factor(train$type)
label_mapping <- levels(train$type)
train_labels <- as.integer(train$type) - 1  # XGBoost needs 0-based labels
#-------------------------------
# One-hot encode predictors
#-------------------------------
# Exclude id and outcome
train_matrix <- model.matrix(~ . - type - id, data = train)
test_matrix  <- model.matrix(~ . - id, data = test)
#-------------------------------
# Create XGBoost DMatrix
#-------------------------------
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest  <- xgb.DMatrix(data = test_matrix)
#-------------------------------
# Hyperparameter grid
#-------------------------------
xgb_grid <- expand.grid(
eta = c(0.01, 0.05, 0.1),
max_depth = c(4, 6, 8),
min_child_weight = c(1, 5),
subsample = c(0.8, 1),
colsample_bytree = c(0.8, 1),
nrounds = c(500, 1000)
)
#-------------------------------
# Cross-validation to find best nrounds
#-------------------------------
set.seed(123)
cv_results <- xgb.cv(
params = list(
objective = "multi:softmax",
num_class = 3,
eta = 0.05,
max_depth = 6,
min_child_weight = 1,
subsample = 0.8,
colsample_bytree = 0.8
),
data = dtrain,
nrounds = 1000,
nfold = 5,
early_stopping_rounds = 20,
verbose = 1,
prediction = FALSE
)
best_nrounds <- cv_results$best_iteration
#-------------------------------
# Train final XGBoost model
#-------------------------------
final_model <- xgboost(
data = dtrain,
label = train_labels,
objective = "multi:softmax",
num_class = 3,
nrounds = best_nrounds,
eta = 0.05,
max_depth = 6,
min_child_weight = 1,
subsample = 0.8,
colsample_bytree = 0.8,
verbose = 1
)
#-------------------------------
# Predict on test set
#-------------------------------
preds <- predict(final_model, dtest)
# Convert 0-based integers back to original labels
pred_labels <- label_mapping[preds + 1]
#-------------------------------
# Prepare submission
#-------------------------------
submission <- tibble(
id = test$id,
type = pred_labels
)
View(submission)
write_csv(submission, "submission.csv")
#-------------------------------
# Load data
#-------------------------------
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
# Outcome must be factor
train$type <- as.factor(train$type)
#-------------------------------
# Recipe (one-hot encode predictors)
#-------------------------------
knn_recipe <- recipe(type ~ ., data = train) |>
update_role(id, new_role = "ID") |>  # exclude id from modeling
step_dummy(all_nominal_predictors()) |>
step_zv(all_predictors()) |>         # remove zero-variance columns
step_normalize(all_predictors())     # KNN works better with normalized features
#-------------------------------
# KNN model spec (tuneable)
#-------------------------------
knn_model <- nearest_neighbor(
neighbors = tune(),      # k
weight_func = "rectangular", # uniform weights; could try "inverse"
dist_power = 2           # Euclidean distance
) |>
set_engine("kknn") |>
set_mode("classification")
#-------------------------------
# Workflow
#-------------------------------
knn_wf <- workflow() |>
add_recipe(knn_recipe) |>
add_model(knn_model)
#-------------------------------
# Cross-validation on full train data
#-------------------------------
cv_folds <- vfold_cv(train, v = 5, strata = type)
#-------------------------------
# Hyperparameter grid
#-------------------------------
knn_grid <- grid_regular(
neighbors(),  # try k = 3 to 25
levels = 10
)
#-------------------------------
# Tune hyperparameters
#-------------------------------
knn_tuned <- tune_grid(
knn_wf,
resamples = cv_folds,
grid = knn_grid,
metrics = metric_set(accuracy)
)
View(knn_tuned)
#-------------------------------
# Select best k
#-------------------------------
best_k <- select_best(knn_tuned, metric = "accuracy")
#-------------------------------
# Final workflow with best k
#-------------------------------
final_knn <- finalize_workflow(knn_wf, best_k)
#-------------------------------
# Fit final model on FULL train data
#-------------------------------
final_fit <- fit(final_knn, data = train)
#-------------------------------
# Predict on test.csv
#-------------------------------
test_preds <- predict(final_fit, test) |>
bind_cols(test |> select(id))
View(test_preds)
#-------------------------------
# Prepare Kaggle submission
#-------------------------------
submission <- test_preds |>
select(id, .pred_class) |>
rename(type = .pred_class)
write_csv(submission, "submission.csv")
install.packages("nnet")
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
library(nnet)
# Drop id/type from training features
train <- train %>% select(-id, -type)
test  <- test %>% select(-id)
# One-hot encode 'color' categorical variable
train <- train %>% mutate(color = factor(color)) %>%
model.matrix(~ . - 1, data = .) %>% as.data.frame()
test <- test %>% mutate(color = factor(color)) %>%
model.matrix(~ . - 1, data = .) %>% as.data.frame()
#-------------------------------
# Train/Test Split
#-------------------------------
set.seed(0)
train_index <- createDataPartition(y_train, p = 0.8, list = FALSE)
y_train <- train$type
index_test <- test$id
# Drop id/type from training features
train <- train %>% select(-id, -type)
test  <- test %>% select(-id)
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
y_train <- train$type
index_test <- test$id
# Drop id/type from training features
train <- train %>% select(-id, -type)
test  <- test %>% select(-id)
# One-hot encode 'color' categorical variable
train <- train %>% mutate(color = factor(color)) %>%
model.matrix(~ . - 1, data = .) %>% as.data.frame()
test <- test %>% mutate(color = factor(color)) %>%
model.matrix(~ . - 1, data = .) %>% as.data.frame()
#-------------------------------
# Train/Test Split
#-------------------------------
set.seed(0)
train_index <- createDataPartition(y_train, p = 0.8, list = FALSE)
X_train <- train[train_index, ]
X_validation <- train[-train_index, ]
Y_train <- y_train[train_index]
Y_validation <- y_train[-train_index]
#-------------------------------
# Standardize Features
#-------------------------------
preProc <- preProcess(X_train, method = c("center", "scale"))
X_train_std <- predict(preProc, X_train)
X_validation_std <- predict(preProc, X_validation)
train_std <- predict(preProc, train)
test_std <- predict(preProc, test)
#-------------------------------
# Logistic Regression Model
#-------------------------------
lr_model <- multinom(Y_train ~ ., data = cbind(Y_train, X_train_std))
# Validate on validation set
y_pred_val <- predict(lr_model, X_validation_std)
accuracy <- mean(y_pred_val == Y_validation)
print(paste("Validation Accuracy:", round(accuracy, 3)))
#-------------------------------
# Train on Full Data & Predict Test Set
#-------------------------------
final_lr <- multinom(y_train ~ ., data = cbind(y_train, train_std))
y_test_pred <- predict(final_lr, test_std)
#-------------------------------
# Prepare Submission
#-------------------------------
submission <- data.frame(id = index_test, type = y_test_pred)
write_csv(submission, "submission.csv")
train <- read_csv("train.csv")
test  <- read_csv("test.csv")
y_train <- train$type
x_train <- train %>% select(-color, -id, -type)
# Encode 'type' as factor and then integer (like LabelEncoder)
y_train_factor <- as.factor(y_train)
y_train_numeric <- as.numeric(y_train_factor) - 1  # 0-based encoding
# Encode 'color' for visualization only
color_factor <- as.factor(train$color)
color_numeric <- as.numeric(color_factor) - 1
#-------------------------------
# Visualize: Point Plot
#-------------------------------
library(ggplot2)
#-------------------------------
# Drop 'color' column
#-------------------------------
id_test <- test$id
x_test <- test %>% select(-color, -id)
#-------------------------------
# Grid Search for SVM
#-------------------------------
tune_grid <- expand.grid(
C = c(1, 5, 10, 0.1, 0.01),
gamma = c(0.001, 0.01, 0.05, 0.5, 1)
)
# Create training control for cross-validation
train_control <- trainControl(method = "cv", number = 5)
# Train SVM with radial kernel using caret
svm_model <- train(
x = x_train,
y = y_train_factor,
method = "svmRadial",
tuneGrid = tune_grid,
trControl = train_control,
preProcess = c("center", "scale")
)
# Train SVM with radial kernel using caret
svm_model <- train(
x = x_train,
y = y_train_factor,
method = "svmRadial",
tuneGrid = tune_grid,
trControl = train_control,
preProcess = c("center", "scale")
)
#-------------------------------
# Grid Search for SVM
#-------------------------------
tune_grid <- expand.grid(
C = c(1, 5, 10, 0.1, 0.01),
gamma = c(0.001, 0.01, 0.05, 0.5, 1)
)
# Create training control for cross-validation
train_control <- trainControl(method = "cv", number = 5)
# Train SVM with radial kernel using caret
svm_model <- train(
x = x_train,
y = y_train_factor,
method = "svmRadial",
tuneGrid = tune_grid,
trControl = train_control,
preProcess = c("center", "scale")
)
